logs_dir: ".\\logs"
results_dir: ".\\results"
evaluations_dir: ".\\results\\evaluations"
test_outputs_dir: ".\\results\\test_outputs"
fine_tuning_logs_dir: ".\\results\\tuning_logs"

dataset:
  ag_news:
    validation_size: 20000

A:
  models:
    - name: "bert_base_uncased_pt"
      model_name: "BERT"
      evaluate: False
    - name: "distilbert_base_uncased_pt"
      model_name: "DistilBERT"
      evaluate: False
    - name: "roberta_base_pt"
      model_name: "RoBERTa"
      evaluate: False

B:
  models:
    - name: "B1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B1_v1_BERT"
      model_dir: ".\\B\\models\\B1_v1_BERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B2_v1_DistilBERT"
      model_dir: ".\\B\\models\\B2_v1_DistilBERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B3_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B3_v1_RoBERTa"
      model_dir: ".\\B\\models\\B3_v1_RoBERTa"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B1_v2_BERT"
      model_dir: ".\\B\\models\\B1_v2_BERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B2_v2_DistilBERT"
      model_dir: ".\\B\\models\\B2_v2_DistilBERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B3_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B3_v2_RoBERTa"
      model_dir: ".\\B\\models\\B3_v2_RoBERTa"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5


C:
  models:
    - name: "C1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C1_v1_BERT"
      model_dir: ".\\C\\models\\C1_v1_BERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "C2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C2_v1_DistilBERT"
      model_dir: ".\\C\\models\\C2_v1_DistilBERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "C3_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C3_v1_RoBERTa"
      model_dir: ".\\C\\models\\C3_v1_RoBERTa"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "C1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C1_v2_BERT"
      model_dir: ".\\C\\models\\C1_v2_BERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "C2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C2_v2_DistilBERT"
      model_dir: ".\\C\\models\\C2_v2_DistilBERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "C3_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C3_v2_RoBERTa"
      model_dir: ".\\C\\models\\C3_v2_RoBERTa"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]


D:
  models:
    - name: "D1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D1_v1_BERT"
      model_dir: ".\\D\\models\\D1_v1_BERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "D2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D2_v1_DistilBERT"
      model_dir: ".\\D\\models\\D2_v1_DistilBERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["k_lin"]
    - name: "D3_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D3_v1_RoBERTa"
      model_dir: ".\\D\\models\\D3_v1_RoBERTa"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "D1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D1_v2_BERT"
      model_dir: ".\\D\\models\\D1_v2_BERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "D2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D2_v2_DistilBERT"
      model_dir: ".\\D\\models\\D2_v2_DistilBERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["k_lin"]
    - name: "D3_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D3_v2_RoBERTa"
      model_dir: ".\\D\\models\\D3_v2_RoBERTa"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]


E:
  models:
    - name: "E1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E1_v1_BERT"
      model_dir: ".\\E\\models\\E1_v1_BERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "E2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E2_v1_DistilBERT"
      model_dir: ".\\E\\models\\E2_v1_DistilBERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "E3_v1"
      model_name: "RoBERTa"
      fine_tune: True
      evaluate: True
      checkpoints_dir: ".\\E\\checkpoints\\E3_v1_RoBERTa"
      model_dir: ".\\E\\models\\E3_v1_RoBERTa"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "E1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E1_v2_BERT"
      model_dir: ".\\E\\models\\E1_v2_BERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "E2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E2_v2_DistilBERT"
      model_dir: ".\\E\\models\\E2_v2_DistilBERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "E3_v2"
      model_name: "RoBERTa"
      fine_tune: True
      evaluate: True
      checkpoints_dir: ".\\E\\checkpoints\\E3_v2_RoBERTa"
      model_dir: ".\\E\\models\\E3_v2_RoBERTa"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
