results_dir: ".\\results"

dataset:
  ag_news:
    validation_size: 20000

A: 
  distilbert_base_uncased:
    name: "distilbert_base_uncased_pt"
    model_name: "DistilBERT"
    evaluate: False
  bert_base_uncased:
    name: "bert_base_uncased_pt"
    model_name: "BERT"
    evaluate: False
  bert_large_uncased:
    name: "bert_large_uncased_pt"
    evaluate: False
  roberta_base:
    name: "roberta_base_pt"
    model_name: "RoBERTa"
    evaluate: False

B:
  logs_dir: ".\\B\\logs"
  bert_base_uncased:
    name: "bert_base_uncased_ft_b_v2"
    model_name: "BERT"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\B\\checkpoints\\bert_base_uncased_ft_b_v2"
    model_dir: ".\\B\\models\\bert_base_uncased_ft_b_v2"
    training_args:
      learning_rate: 1e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
  distilbert_base_uncased:
    name: "distilbert_base_uncased_ft_b_v2"
    model_name: "DistilBERT"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\B\\checkpoints\\distilbert_base_uncased_ft_b_v2"
    model_dir: ".\\B\\models\\distilbert_base_uncased_ft_b_v2"
    training_args:
      learning_rate: 1e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
  roberta_base:
    name: "roberta_base_ft_b_v2"
    model_name: "RoBERTa"
    fine_tune: False
    evaluate: True
    checkpoints_dir: ".\\B\\checkpoints\\roberta_base_ft_b_v2"
    model_dir: ".\\B\\models\\roberta_base_ft_b_v2"
    training_args:
      learning_rate: 1e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5


C:
  logs_dir: ".\\C\\logs"
  bert_base_uncased:
    name: "bert_base_uncased_ft_c_v1"
    model_name: "BERT"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\C\\checkpoints\\bert_v1"
    model_dir: ".\\C\\models\\bert_v1"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
      lora_config:
        r: 8
        alpha: 32
        dropout: 0.01
        target_modules: ["query"]
  distilbert_base_uncased:
    name: "distilbert_base_uncased_ft_c_v1"
    model_name: "DistilBERT"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\C\\checkpoints\\distilbert_v1"
    model_dir: ".\\C\\models\\distilbert_v1"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
      lora_config:
        r: 8
        alpha: 32
        dropout: 0.01
        target_modules: ["q_lin"]
  roberta_base:
    name: "roberta_base_ft_c_v1"
    model_name: "RoBERTa"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\C\\checkpoints\\roberta_v1"
    model_dir: ".\\C\\models\\roberta_v1"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
      lora_config:
        r: 8
        alpha: 32
        dropout: 0.01
        target_modules: ["query"]
