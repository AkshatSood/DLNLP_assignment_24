dataset:
  ag_news:
    validation_size: 20000

A: 
  output_dir: ".\\A\\results"
  distilbert_base_uncased:
    name: "distilbert_base_uncased_pt"
    evaluate: False
  bert_base_uncased:
    name: "bert_base_uncased_pt"
    evaluate: False
  bert_large_uncased:
    name: "bert_large_uncased_pt"
    evaluate: False
  roberta_base:
    name: "roberta_base"
    evaluate: False

B:
  logs_dir: ".\\B\\logs"
  bert_base_uncased:
    name: "bert_base_uncased_ft_b"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\B\\checkpoints\\bert_base_uncased_ft_b"
    model_dir: ".\\B\\models\\bert_base_uncased_ft_b"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
  distilbert_base_uncased:
    name: "distilbert_base_uncased_ft_b"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\B\\checkpoints\\distilbert_base_uncased_ft_b"
    model_dir: ".\\B\\models\\distilbert_base_uncased_ft_b"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
  roberta_base:
    name: "roberta_base_ft_b"
    fine_tune: True
    evaluate: False
    checkpoints_dir: ".\\B\\checkpoints\\roberta_base_ft_b"
    model_dir: ".\\B\\models\\roberta_base_ft_b"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5


C:
  logs_dir: ".\\C\\logs"
  bert_base_uncased:
    name: "bert_base_uncased_ft_c"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\C\\checkpoints\\bert_base_uncased_ft_c"
    model_dir: ".\\C\\models\\bert_base_uncased_ft_c"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
      lora_config:
        r: 8
        alpha: 32
        dropout: 0.01
        target_modules: ["query"]
  distilbert_base_uncased:
    name: "distilbert_base_uncased_ft_c"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\C\\checkpoints\\distilbert_base_uncased_ft_c"
    model_dir: ".\\C\\models\\distilbert_base_uncased_ft_c"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
      lora_config:
        r: 8
        alpha: 32
        dropout: 0.01
        target_modules: ["q_lin"]
  roberta_base:
    name: "roberta_base_ft_c"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\C\\checkpoints\\roberta_base_ft_c"
    model_dir: ".\\C\\models\\roberta_base_ft_c"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
      lora_config:
        r: 8
        alpha: 32
        dropout: 0.01
        target_modules: ["query"]



  # distilbert_base_uncased:
  #   log_name: "DistilBertUncased_LoRA-SEQ_CLS-q_lin.csv"
