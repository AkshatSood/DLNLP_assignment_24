results_dir: ".\\results"
evaluations_dir: ".\\results\\evaluations"
test_outputs_dir: ".\\results\\test_outputs"
fine_tuning_logs_dir: ".\\results\\tuning_logs"

dataset:
  ag_news:
    validation_size: 20000

A:
  models:
    - name: "bert_base_uncased_pt"
      model_name: "BERT"
      evaluate: False
    - name: "distilbert_base_uncased_pt"
      model_name: "DistilBERT"
      evaluate: False
    - name: "roberta_base_pt"
      model_name: "RoBERTa"
      evaluate: False

B:
  models:
    - name: "B1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: True
      checkpoints_dir: ".\\B\\checkpoints\\bert_base_uncased_ft_b_v1"
      model_dir: ".\\B\\models\\bert_base_uncased_ft_b_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: True
      checkpoints_dir: ".\\B\\checkpoints\\distilbert_base_uncased_ft_b_v1"
      model_dir: ".\\B\\models\\distilbert_base_uncased_ft_b_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B3_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: True
      checkpoints_dir: ".\\B\\checkpoints\\roberta_base_ft_b_v1"
      model_dir: ".\\B\\models\\roberta_base_ft_b_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: True
      checkpoints_dir: ".\\B\\checkpoints\\bert_base_uncased_ft_b_v2"
      model_dir: ".\\B\\models\\bert_base_uncased_ft_b_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: True
      checkpoints_dir: ".\\B\\checkpoints\\distilbert_base_uncased_ft_b_v2"
      model_dir: ".\\B\\models\\distilbert_base_uncased_ft_b_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B3_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: True
      checkpoints_dir: ".\\B\\checkpoints\\roberta_base_ft_b_v2"
      model_dir: ".\\B\\models\\roberta_base_ft_b_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5


C:
  models:
    - name: "bert_base_uncased_ft_c_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\bert_v1"
      model_dir: ".\\C\\models\\bert_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "distilbert_base_uncased_ft_c_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\distilbert_v1"
      model_dir: ".\\C\\models\\distilbert_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "roberta_base_ft_c_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\roberta_v1"
      model_dir: ".\\C\\models\\roberta_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "bert_base_uncased_ft_c_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\bert_v2"
      model_dir: ".\\C\\models\\bert_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "distilbert_base_uncased_ft_c_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\distilbert_v2"
      model_dir: ".\\C\\models\\distilbert_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "roberta_base_ft_c_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\roberta_v2"
      model_dir: ".\\C\\models\\roberta_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]


D:
  models:
    - name: "bert_base_uncased_ft_d_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\bert_v1"
      model_dir: ".\\D\\models\\bert_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "distilbert_base_uncased_ft_d_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\distilbert_v1"
      model_dir: ".\\D\\models\\distilbert_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["k_lin"]
    - name: "roberta_base_ft_d_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\roberta_v1"
      model_dir: ".\\D\\models\\roberta_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "bert_base_uncased_ft_d_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\bert_v2"
      model_dir: ".\\D\\models\\bert_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "distilbert_base_uncased_ft_d_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\distilbert_v2"
      model_dir: ".\\D\\models\\distilbert_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["k_lin"]
    - name: "roberta_base_ft_d_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\roberta_v2"
      model_dir: ".\\D\\models\\roberta_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]


E:
  models:
    - name: "bert_base_uncased_ft_e_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\bert_v1"
      model_dir: ".\\E\\models\\bert_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "distilbert_base_uncased_ft_e_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\distilbert_v1"
      model_dir: ".\\E\\models\\distilbert_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "roberta_base_ft_e_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\roberta_v1"
      model_dir: ".\\E\\models\\roberta_v1"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "bert_base_uncased_ft_e_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\bert_v2"
      model_dir: ".\\E\\models\\bert_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "distilbert_base_uncased_ft_e_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\distilbert_v2"
      model_dir: ".\\E\\models\\distilbert_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "roberta_base_ft_e_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\roberta_v2"
      model_dir: ".\\E\\models\\roberta_v2"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
