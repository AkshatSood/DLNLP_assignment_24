logging:
  logs_dir: ".\\logs"
  results_dir: ".\\results"
  evaluations_dir: ".\\results\\evaluations"
  test_outputs_dir: ".\\results\\test_outputs"
  fine_tuning_logs_dir: ".\\results\\tuning_logs"
  plots_dir: ".\\results\\plots"
  create_log: True
  create_evaluations_summary: False
  create_fine_tuning_logs_summary: False
  create_summary_plots: False

dataset:
  ag_news:
    validation_size: 20000

A:
  naive_bayes:
    name: "A0"
    model_name: "NaiveBayes"
    execute: False
    grid_search: False

  models:
    - name: "A1"
      model_name: "BERT"
      evaluate: False
    - name: "A2"
      model_name: "DistilBERT"
      evaluate: False
    - name: "A3"
      model_name: "RoBERTa"
      evaluate: False

B:
  models:
    - name: "B1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B1_v1_BERT"
      model_dir: ".\\B\\models\\B1_v1_BERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B2_v1_DistilBERT"
      model_dir: ".\\B\\models\\B2_v1_DistilBERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B3_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B3_v1_RoBERTa"
      model_dir: ".\\B\\models\\B3_v1_RoBERTa"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B1_v2_BERT"
      model_dir: ".\\B\\models\\B1_v2_BERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B2_v2_DistilBERT"
      model_dir: ".\\B\\models\\B2_v2_DistilBERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5
    - name: "B3_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\B\\checkpoints\\B3_v2_RoBERTa"
      model_dir: ".\\B\\models\\B3_v2_RoBERTa"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 5

C:
  models:
    - name: "C1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C1_v1_BERT"
      model_dir: ".\\C\\models\\C1_v1_BERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "C2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C2_v1_DistilBERT"
      model_dir: ".\\C\\models\\C2_v1_DistilBERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "C3_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C3_v1_RoBERTa"
      model_dir: ".\\C\\models\\C3_v1_RoBERTa"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "C1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C1_v2_BERT"
      model_dir: ".\\C\\models\\C1_v2_BERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "C2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C2_v2_DistilBERT"
      model_dir: ".\\C\\models\\C2_v2_DistilBERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "C3_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\C\\checkpoints\\C3_v2_RoBERTa"
      model_dir: ".\\C\\models\\C3_v2_RoBERTa"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]

D:
  models:
    - name: "D1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D1_v1_BERT"
      model_dir: ".\\D\\models\\D1_v1_BERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "D2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D2_v1_DistilBERT"
      model_dir: ".\\D\\models\\D2_v1_DistilBERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["k_lin"]
    - name: "D3_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D3_v1_RoBERTa"
      model_dir: ".\\D\\models\\D3_v1_RoBERTa"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "D1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D1_v2_BERT"
      model_dir: ".\\D\\models\\D1_v2_BERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "D2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D2_v2_DistilBERT"
      model_dir: ".\\D\\models\\D2_v2_DistilBERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["k_lin"]
    - name: "D3_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\D\\checkpoints\\D3_v2_RoBERTa"
      model_dir: ".\\D\\models\\D3_v2_RoBERTa"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]

E:
  models:
    - name: "E1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E1_v1_BERT"
      model_dir: ".\\E\\models\\E1_v1_BERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "E2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E2_v1_DistilBERT"
      model_dir: ".\\E\\models\\E2_v1_DistilBERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "E3_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E3_v1_RoBERTa"
      model_dir: ".\\E\\models\\E3_v1_RoBERTa"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "E1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E1_v2_BERT"
      model_dir: ".\\E\\models\\E1_v2_BERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]
    - name: "E2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E2_v2_DistilBERT"
      model_dir: ".\\E\\models\\E2_v2_DistilBERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["q_lin"]
    - name: "E3_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\E\\checkpoints\\E3_v2_RoBERTa"
      model_dir: ".\\E\\models\\E3_v2_RoBERTa"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["query"]

F:
  models:
    - name: "F1_v1"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\F\\checkpoints\\F1_v1_BERT"
      model_dir: ".\\F\\models\\F1_v1_BERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "F2_v1"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\F\\checkpoints\\F2_v1_DistilBERT"
      model_dir: ".\\F\\models\\F2_v1_DistilBERT"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["k_lin"]
    - name: "F3_v1"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\F\\checkpoints\\F3_v1_RoBERTa"
      model_dir: ".\\F\\models\\F3_v1_RoBERTa"
      training_args:
        learning_rate: 5e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "F1_v2"
      model_name: "BERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\F\\checkpoints\\F1_v2_BERT"
      model_dir: ".\\F\\models\\F1_v2_BERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
    - name: "F2_v2"
      model_name: "DistilBERT"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\F\\checkpoints\\F2_v2_DistilBERT"
      model_dir: ".\\F\\models\\F2_v2_DistilBERT"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["k_lin"]
    - name: "F3_v2"
      model_name: "RoBERTa"
      fine_tune: False
      evaluate: False
      checkpoints_dir: ".\\F\\checkpoints\\F3_v2_RoBERTa"
      model_dir: ".\\F\\models\\F3_v2_RoBERTa"
      training_args:
        learning_rate: 1e-5
        per_device_train_batch_size: 8
        per_device_eval_batch_size: 8
        weight_decay: 0.01
        epochs: 10
        lora_config:
          r: 8
          alpha: 32
          dropout: 0.01
          target_modules: ["key"]
