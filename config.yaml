dataset:
  ag_news:
    validation_size: 20000

A: 
  output_dir: ".\\A\\results"
  distilbert_base_uncased:
    name: "distilbert_base_uncased_pt"
    evaluate: False
  bert_base_uncased:
    name: "bert_base_uncased_pt"
    evaluate: False
  bert_large_uncased:
    name: "bert_large_uncased_pt"
    evaluate: False
  roberta_base:
    name: "roberta_base"
    evaluate: False

B:
  logs_dir: ".\\B\\logs"
  bert_base_uncased:
    name: "bert_base_uncased_ft_b"
    fine_tune: True
    evaluate: False
    checkpoints_dir: ".\\B\\checkpoints\\bert_base_uncased_ft_b"
    model_dir: ".\\B\\models\\bert_base_uncased_ft_b"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5
  distilbert_base_uncased:
    name: "distilbert_base_uncased_ft_b"
    fine_tune: False
    evaluate: False
    checkpoints_dir: ".\\B\\checkpoints\\distilbert_base_uncased_ft_b"
    model_dir: ".\\B\\models\\distilbert_base_uncased_ft_b"
    training_args:
      learning_rate: 5e-5
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      weight_decay: 0.01
      epochs: 5



  # distilbert_base_uncased:
  #   log_name: "DistilBertUncased_LoRA-SEQ_CLS-q_lin.csv"
